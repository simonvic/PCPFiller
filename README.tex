\documentclass[12pt]{report}
\usepackage[a4paper, total={7in, 10in}]{geometry}
\usepackage{graphicx}
\usepackage{hyperref}
\usepackage{listings}
\usepackage{parskip}
\usepackage[table,xcdraw]{xcolor}

\geometry{a4paper}
\usepackage{color}
\definecolor{hi_comment}{rgb}{0.5, 0.5, 0.5}
\definecolor{hi_keyword}{rgb}{0.13, 0.13, 1.0}
\definecolor{hi_string}{rgb}{0.0, 0.5, 0.0}
\definecolor{hi_rule}{rgb}{0.13, 0.13, 1.0}
\definecolor{hi_background}{rgb}{0.94,0.95,0.96}
\lstset{language=Java,
	basicstyle=\small\ttfamily,
	columns=fixed,
	breaklines=false,
	tabsize=4,
	showstringspaces=false,
	commentstyle = \color{hi_comment},
	keywordstyle = \color{hi_keyword},
	stringstyle = \color{hi_string},
	rulecolor = \color{hi_rule},
	backgroundcolor=\color{hi_background},
}




\title{PCPFiller}
\author{Simone Vicinanza}
\date{}

\begin{document}
\maketitle
\tableofcontents

\newpage
\section{PCPFiller}

\textbf{PCPFiller} (PC Part Picker Filler) è una utility CLI destinata al
preprocessing di dataset.

Trovare datasets di componenti hardware per PC per un qualsiasi progetto di ML/DL, che siano
decenti e reperibili gratuitamente non è per niente facile; la maggior parte dei datasets
disponibili online sono incompleti, molto obsoleti, troppo piccoli per il training di una AI e
spesso anche incorretti.

\textbf{PCPFiller} is offre di costruire e fornire datasets completi e di dimensioni sufficienti per allenare
una AI per scopi didattici e non.

\section{Quick start}

PCPFiller consiste in un helper script python (\texttt{PCPFetcher.py}) il quale ha il compito di
scaricare dei dataset iniziali, i quali saranno poi utilizzati dal modulo Java che si occuperà del
"filling" dei dati.

Per una list di comandi e opzioni di `PCPFetcher.py`, consultare la help page con il seguente comando:
\begin{lstlisting}
$ python ./PCPFetcher.py --help
\end{lstlisting}

Per il modulo in java invece:
\begin{lstlisting}
$ java -jar ./PCPFiller.jar --help
\end{lstlisting}

\textbf{NOTA}: per semplicità, da ora in poi il modulo Python e il modulo Java saranno invocati
rispettivamente con i comandi:
\begin{lstlisting}
$ PCPFetcher [opzioni]
$ PCPFiller [opzioni]
\end{lstlisting}

Esempio completo di fetching e filling di un dataset (memorie RAM):
\begin{lstlisting}
$ PCPFetcher --fetch memory --region it
$ PCPFiller --part memory --from-json memory.json \
	--save-model memory.model \
	--save-dataset dataset.arff \
	--out-format ARFF
\end{lstlisting}



\newpage
\subsection{Fetching di dataset iniziali}

Per prima cosa, \textbf{PCPFiller} scaricherà una lista di componenti hardware dal noto \\
sito \underline{\textit{PCPartPicker.com}.} In tale lista sono inclusi componenti principali, quali
CPU, GPU, RAM, mouse, monitor, HDD, e altre periferiche secondarie.
Per scaricare i componenti, eseguire il seguente comando:
\begin{lstlisting}
$ PCPFetcher --fetch <tipo componente>
\end{lstlisting}

Per sapere la lista dei componenti attualmente supportati a PCPFetcher, eseguire il seguente comando:
\begin{lstlisting}
$ PCPFetcher --supported-parts
\end{lstlisting}

Il download dei componenti è possibile grazie alle ottime API per python \\
fornite da \underline{\textit{PCPartPicker.com}} stesso (\underline{\textit{https://pypi.org/project/pcpartpicker}}),
ottenibili con \textit{pip}.

\textbf{NOTA}: quando si scaricano i componenti, assicurarsi di settare la \textit{region} correttamente.
\begin{lstlisting}
$ PCPFetcher --fetch <tipo componente> --region <regione>
\end{lstlisting}

Effettuare il fetching con una regione errata potrebbe risultare in download di dataset diversi
o addirittura un fallimento del download.

Per sapere la lista delle regioni attualmente supportate, eseguire il seguente comando
\begin{lstlisting}
$ PCPFetcher --supported-regions
\end{lstlisting}

\newpage
\subsection{Filling del dataset}

\textbf{PCPFiller} (modulo Java) si occpuerà poi di fare il parsing di tali componenti, manipolando
alcuni dati per facilitarne l'elaborazione, per poi convertirli in formato \textit{CSV}, in modo da
renderli utilizzabili da altri strumenti come Weka (GUI e API) per eventuale analisi dati, e con lo
scopo di poter procedere al "filling" di eventuali dati mancanti.

\textbf{NOTA}: le directory di input/output di PCPFiller sono di default \textit{./parts} e
\textit{./parts/formatted}. Tali percorsi possono essere cambiati; consultare la help page.

Il modulo Java si occuperà del filling dei dati attraverso un modello di ML, che può essere allenato e salvato...
\begin{lstlisting}
$ PCPFiller --part <pcpart> --from-json <json-dataset> \
	--save-model <model-file>
\end{lstlisting}

... oppure caricato se già allenato in precedenza
\begin{lstlisting}
$ PCPFiller --part <pcpart> --from-json <json-dataset> \
	--load-model <model-file>
\end{lstlisting}

Il dataset in output dopo la fase di filling, potrà essere salvato nei vari formati supportati
\begin{lstlisting}
$ PCPFiller --part <pcpart> --from-json <json-dataset> \
	--save-dataset <output-dataset> \
	--out-format <output-format>
\end{lstlisting}

\newpage
\section{Descrizione dell'agente intelligente}

L'obiettivo dell'agente è quello di valutare la relazione tra le varie statistiche di un componente,
per poi essere in grado di completare eventuali dati mancanti (continui e nominali).

\subsection{PEAS}

\begin{itemize}
	\item\textbf{Performance}\\
		La performance dell'agente è dettata dalla precisione e accuratezza dei dati mancanti predetti
	\item\textbf{Enviroment}
		\begin{itemize}
			\item \textbf{Completamente osservabile}, dato che ha accesso a tutte le informazioni di un componente
			\item \textbf{Deterministico}, in quanto i dati predetti dipendono solamente dallo stato iniziale dei componenti e dalle modifiche dell'agente
			\item \textbf{Sequenziale}, in quanto i dati in output possono variare in baso alle iterazioni precedenti
			\item \textbf{Statico}, i dati non variano mentre l'agente sta operando
			\item \textbf{Singolo agente}, in quanto PCPFiller è l'unico a manipolare i dati
			\item \textbf{Continuo}, la decisione del dato predetto si evolve in modo continuo
		\end{itemize}
	\item\textbf{Actuators}\\
		Gli attuatori consistono nei dati predetti inseriti nel dataset
	\item\textbf{Sensors}\\
		I sensori dell'agente consistono nei dati già presenti di un dato componente nel dataset
\end{itemize}

\subsection{Osservazioni sull'agente}

\textbf{PCPFiller}, con qualche modifica, potrebbe essere adattato per poter lavorare in un ambiente
dinamico e multi agente, in modo da poter predirre i risultati in modo dinamico dato che il mondo
economico è sempre in evoluzione.

Si potrebbe tener conto del trend di popolarità del manufacturer del componente
hardware, eventuali festività che potrebbero portare a cambiamenti (ad esempio al prezzo) e tante
altre variabili dinamiche.

Però, come menzionato prima, lo scopo di PCPFiller è solo quello di completare e fornire datasets per
altri eventuali progetti didattici di ML/DL.

\newpage
\section{Scelta di dataset di partenza}
Per poter fornire un datasets utilizzabile, PCPFiller necessità di alcuni dati di partenza per il
training del modello di ML che avrà poi lo scopo di predirre i dati mancanti.

L'idea della creazione di un dataset da zero è stata scartata immediatamente per evitare di introdurre
un ulteriore possibilità di errore.

Quindi, inizialmente si aveva pensato di fare scraping su siti di eShopping (es: Amazon, NewEgg etc.),
ma anche ciò è risultato impossibile da realizzare, dato che un singolo sito non forniva abbastanza dati,
e utilizzare piu siti significava dover rendere PCPFiller compatibile con una moltitudine di formati
dati, il che sarebbe diventato presto impossibile da mantere con un qualisasi cambiamento dei suddetti siti.\\
Oltretutto, lo scraping potrebbe aver implicazioni legali, in quanto la maggior parte dei siti non lo permettte.

Si è quindi ricorso a \underline{\textit{PCPartPicker.com}}, un sito che offre un'interfaccia per
creare delle PC build selezionando i vari componenti; il database di PCPartPicker contiente una buona
mole di dati, e come menzionato in precendenza, offre anche delle API per poter accedere a tali dati.

Le GPU e RAM erano i dataset di partenza con piu dati disponibili.
\begin{itemize}
	\item Nel caso delle GPU, le entries sono ~4400.\\
		Rimuovendo le entries incomplete si arriva a ~350, quindi con una notevole perdita del ~90\%.
	\item Nel caso delle RAM, le entries sono ~7000.\\
		Rimuovendo le entries incomplete si arriva a ~1800, quindi con una perdita del ~70\%.
\end{itemize}
Come previsto anche \underline{\textit{PCPartPicker.com}}, nonostante i dataset \\relativamente grandi,
presenta una notevole mole di dati mancanti.

Si è quindi deciso di operare inizialmente al filling del prezzo delle RAM e in futuro di espandere
il modello su altri attributi e su altri tipi di componenti.

\newpage
\section{Analisi dati disponibili}

Segue una descrizione generale dei dati disponibili per le RAM e l'eventuale utilità per lo scopo predisposto da PCPFiller
\begin{itemize}
	\item \textbf{Brand} (\textit{nominal})
		\begin{itemize}
			\item Descrizione: Nome del brand della casa produttrice
			\item Utilità: Potrebbe essere molto utile soprattutto nella predizione di prezzo. Molti brand sono noti per sovrapprezzare i propri prodotti.
		\end{itemize}
	\item \textbf{Model} (\textit{nominal})
		\begin{itemize}
			\item Descrizione: Nome del modello
			\item Utilità: Non molto utile, in quando è insolito che due prodotti condividano lo stesso nome; porterebbe solamente all'inquinamento della predizione
		\end{itemize}
	\item \textbf{Module Type} (\textit{nominal})
		\begin{itemize}
			\item Descrizione: Tipo del modulo (DDR2/3/4).\\Rappresenta la "generazione" del modulo
			\item Utilità: Molto utile, dato che tipo di moduli diversi fanno variare molto prezzo\\ ed altre statistiche come frequenza e dimensione modulo
		\end{itemize}
	\item \textbf{Speed (cycles)} (\textit{numeric})
		\begin{itemize}
			\item Descrizione: Frequenza del modulo, rappresentata in hertz (convertita in MHz in fase di preprocessing)
			\item Utilità: Decisamente utile, in quanto strettamente correlata con altri parametri
		\end{itemize}
	\item \textbf{Modules number} (\textit{numeric})
		\begin{itemize}
			\item Descrizione: Quantità di moduli
			\item Utilità: Strettamente correlata all dimensione e prezzo di un singolo modulo (1x8GB, 2x4GB, 2x16GB etc.)
		\end{itemize}
	\item \textbf{Price / GB} (\textit{numeric})
		\begin{itemize}
			\item Descrizione: Prezzo in Euro per un GB
			\item Utilità: Dato derivato da prezzo e dimensione/quantità dei moduli.
		\end{itemize}
	\item \textbf{Color} (\textit{nominal})
		\begin{itemize}
			\item Descrizione: Colore dell'involucro
			\item Utilità: Alcuni colori (es: Gold, Silver) potrebbero essere correlati a prezzo e brand.
		\end{itemize}
	\item \textbf{FW Latency} (\textit{numeric})
		\begin{itemize}
			\item Descrizione: First Word Latency, latenza (ns) tempo di accesso (performance del modulo)
			\item Utilità: Strettamente correlato ad altri parametri
		\end{itemize}
	\item \textbf{CAS timing} (\textit{numeric})
		\begin{itemize}
			\item Descrizione: Latenza di "Column Access Strobe"
			\item Utilità: Strettamente correlato ad altri parametri
		\end{itemize}
	\item \textbf{ECC} (\textit{nominal})
		\begin{itemize}
			\item Descrizione: Error Correction, capacità di correzioni errori (convertita in true/false in fase di preprocessing)
			\item Utilità: Solitamente la funzionalità di ECC è presente in moduli più pregiati. Quindi correlata ad altri parametri
		\end{itemize}
	\item \textbf{Price} (\textit{numeric})
		\begin{itemize}
			\item Descrizione: Prezzo in Euro
			\item Utilità: Decisamente utile
		\end{itemize}
\end{itemize}

Anche senza un'attenta analisi dei dati, possiamo confidentemente rimuovere il campo \textit{Model} e \textit{Price per GB}.

Analizzando i dati con Weka, possiamo risalire alle seguenti informazioni

\includegraphics[width=\linewidth]{tex/img/attributes_stats.png}

Dei dati piu rilevanti, possiamo dire:
\begin{itemize}
	\item La generazione piu offerta è DDR4, seguita da DDR3 e DDR2
	\item La frequenza media e di circa 2500 MHz con una standard deviation di ~840
	\item La maggior parte dei prodotti vengono venduti in batch da 2 con una dimensione media di 10GB
	\item Moduli con ECC non sono molto comuni
	\item Il prezzo può arrivare anche a 2800 Euro, con una media di ~200 Euro e standard deviation di 220
\end{itemize}

\newpage
\subsection{Relazioni con attributo prezzo}
Dato che ci interessa principalmente la previsione di campi correlati al prezzo,
commentiamo la loro relazione

\textbf{NOTA}: è stato applicato un po' di jitter sui dati per migliorarne la visualizzazione

\subsubsection{Brand}
\includegraphics[width=\linewidth]{tex/img/price_brand.png}

Come previsto, alcuni brand più blasonati sono soliti scegliere prezzi piu alti per i propri prodotti

\subsubsection{Generazione modulo}
\includegraphics[width=\linewidth]{tex/img/price_moduleType.png}

Nessuna sorpresa, le ultime generazioni hanno un prezzo piu elevato.

Lo stesso possiamo dire per gli altri parametri di performance del modulo: 
maggiori performance risultano in un prezzo piu alto.

\subsubsection{Frequenza}
\includegraphics[width=\linewidth]{tex/img/price_speed.png}
\subsubsection{Dimensione modulo}
\includegraphics[width=\linewidth]{tex/img/price_moduleSize.png}
\subsubsection{First Word Latency}
\includegraphics[width=\linewidth]{tex/img/price_fwlatency.png}
\subsubsection{Overview}
\includegraphics[width=\linewidth]{tex/img/attributes_overview.png}
Una overview delle relazioni tra i vari campi


\newpage
\section{Analisi relazione tra attributi}

Per confermare le osservazioni fatte e per avere una visione più accurata della relazione tra
gli attributi, utilizziamo ancora una volta Weka.

\textit{SPOILER} Il campo color è stato scartato. Nonostante il colore potrebbe essere parzialmente
utile per la previsione del prezzo, in seguito alle precedenti osservazioni (e futuri test di
regressione), si è deciso di rimuoverlo perchè comportava solamente un incremento di complessità per
il nostro modello, senza apportare netti benefici.

\subsection{Correlation Attribute Evaluation}
L'algoritmo \textit{CorrelationAttributeEval} valuta il "valore" di un attributo misurando la
\textbf{correlazione di Pearson} tra di esso e l'attributo scelto come classe.

Si sceglie quindi il prezzo come classe, e come metodo di ricerca si usa il \textit{Ranker}.

\textbf{NOTA}: L'analisi viene effettuata su tutto il dataset (non vengono usate partizioni)
\begin{table}[!htb]
	\centering
	\begin{tabular}{ll}
		Valore  & Campo             \\
		0.6974  & Modules number    \\
		0.4739  & Module size       \\
		0.4371  & Speed             \\
		0.3142  & CAS timing        \\
		0.2878  & Module type (gen) \\
		0.1201  & Brand             \\
		0.0917  & Color             \\
		0.0208  & ECC               \\
		-0.3646 & FW latency       
	\end{tabular}
\end{table}

Come previsto il numero dei moduli, la dimensione e la frequenza sono i parametri che piu impattano
il prezzo, seguiti poi dai vari parametri di performance.

\textbf{NOTA}: del campo \textit{FW latency}, si dovrebbe prendere il valore assoluto, dato che con
l'aumentare della latenza, le performance diminuiscono, e quindi anche il prezzo.

Ripetiamo l'analisi anche con una PCA.

\newpage
\subsection{Principal Components Analysis}
Anche in questo caso si sceglie il prezzo come classe, e come metodo di ricerca si usa il \textit{Ranker}.

\textbf{NOTA}: L'analisi viene effettuata su tutto il dataset (non vengono usate partizioni)

\begin{lstlisting}[breaklines=true]
Ranked attributes:
0.8454    1 -0.443speed-0.436module_type=DDR4-0.423cas_timing+0.409module_type=DDR3+0.282first_word_latency...
0.7829    2 0.526error_correction=True+0.356module_size+0.341brand=Samsung+0.32 brand=Crucial+0.303first_word_latency...
0.735     3 0.735brand=Corsair-0.54brand=G.Skill+0.264number_of_modules-0.137brand=Patriot+0.132module_size...
0.6891    4 0.448brand=G.Skill-0.371brand=Patriot-0.328module_type=DDR2+0.263number_of_modules-0.261brand=ADATA...
0.647     5 0.498module_type=DDR2+0.356brand=OCZ-0.353brand=Kingston+0.282brand=Mushkin+0.257brand=G.Skill...
0.6078    6 0.554brand=Kingston+0.403brand=OCZ+0.334module_type=DDR2-0.262brand=Patriot-0.237brand=GeIL...
0.5707    7 -0.644brand=Crucial+0.311brand=Kingston-0.296brand=Klevv-0.231brand=OCZ+0.229brand=Samsung...
0.5346    8 0.647brand=Patriot-0.54brand=Team-0.365brand=Mushkin+0.231brand=Crucial-0.185brand=ADATA...
0.4987    9 0.494brand=Team-0.488brand=ADATA+0.34 brand=Samsung+0.32 brand=Patriot-0.316brand=Crucial...
0.4631   10 0.518brand=ADATA+0.464brand=Thermaltake-0.326brand=Team+0.312brand=Samsung-0.294brand=Crucial...
[...]
\end{lstlisting}


\newpage
\section{Processing dei dati}
Il prezzo è un valore continuo, possiamo quindi scegliere vari algoritmi specializziati per regressione con valori numerici:

\begin{itemize}
	\item LinearRegression
	\item Alberi
		\begin {itemize}
	\item RandomTree
	\item RandomForest
	\item M5P
\end{itemize}
\end{itemize}

Per quanto riguarda il testing, creare un dataset specificatamente per esso era fuori discussione.

Si è quindi optato per una k-fold cross-validation. I test sono stati effettuati con 5, 10 e 15
partizioni (fold), data la ridotta dimensione del dataset, i risultati migliori si sono ottenuti con 10 fold.

\textbf{NOTA}: dato che stiamo cercando di creare un modello per la predizione del prezzo, il nostro obiettivo
è quello di ridurre quanto più possibile lo scarto quadratico.

\newpage
\subsection{Linear regression}

\subsubsection{Modello risultante}
\begin{lstlisting}[breaklines=true]
price =

   66.561  * brand=HP,OCZ,Kingston,PNY,ADATA,Team,IBM,Thermaltake,Crucial,Klevv,Samsung,G.Skill,Corsair,Gigabyte +
 -110.007  * brand=OCZ,Kingston,PNY,ADATA,Team,IBM,Thermaltake,Crucial,Klevv,Samsung,G.Skill,Corsair,Gigabyte +
   27.7063 * brand=Kingston,PNY,ADATA,Team,IBM,Thermaltake,Crucial,Klevv,Samsung,G.Skill,Corsair,Gigabyte +
   16.9202 * brand=PNY,ADATA,Team,IBM,Thermaltake,Crucial,Klevv,Samsung,G.Skill,Corsair,Gigabyte +
  -39.1303 * brand=IBM,Thermaltake,Crucial,Klevv,Samsung,G.Skill,Corsair,Gigabyte +
  -19.4201 * brand=Thermaltake,Crucial,Klevv,Samsung,G.Skill,Corsair,Gigabyte +
   41.2542 * brand=Crucial,Klevv,Samsung,G.Skill,Corsair,Gigabyte +
  -17.8709 * brand=Klevv,Samsung,G.Skill,Corsair,Gigabyte +
  -28.8788 * brand=Samsung,G.Skill,Corsair,Gigabyte +
   57.8274 * brand=G.Skill,Corsair,Gigabyte +
   15.5456 * brand=Corsair,Gigabyte +
 -191.5702 * module_type=DDR3,DDR4 +
 -149.078  * module_type=DDR4 +
  104.3092 * number_of_modules +
   10.9041 * module_size +
  -18.723  * first_word_latency +
   20.0331 * cas_timing +
  -69.9652 * error_correction=False +
  137.2024
\end{lstlisting}

\newpage
\subsubsection{Risultati}
\begin{table}[ht]
	\centering
	\begin{tabular}{p{0.4\linewidth}p{0.4\linewidth}}
		Coefficiente di correlazione & 0.8056     \\
		Errore medio assoluto        & 81.1316    \\
		Errore quadratico medio      & 133.8985   \\
		Errore assoluto relativo     & 59.6785 \% \\
		Errore quadratico relativo   & 59.2254 \% \\
	\end{tabular}
\end{table}

\includegraphics[width=\linewidth]{tex/img/result_linearregression.png}

L'algoritmo di linear regression è quindi risultato discreto. Come si può vedere tende a sovrastimare
il prezzo.

Esploriamo altri algoritmi.

\newpage
\subsection{RandomTree}

\subsubsection{Modello risultante}
\includegraphics[width=\linewidth]{tex/img/model_randomTree.png}

\newpage
\subsubsection{Risultati}
\begin{table}[ht]
	\centering
	\begin{tabular}{p{0.4\linewidth}p{0.4\linewidth}}
		Coefficiente di correlazione & 0.8915     \\
		Errore medio assoluto        & 53.9916    \\
		Errore quadratico medio      & 105.6178   \\
		Errore assoluto relativo     & 39.7149 \% \\
		Errore quadratico relativo   & 46.7164 \% \\
	\end{tabular}
\end{table}
\includegraphics[width=\linewidth]{tex/img/result_randomTree.png}

Come si può notare si ottengono risultati migliori, anche se l'albero risultante è molto grande,
probabilmente a causa dell'attributo Brand; anche senza il Brand la performance non cambiava di molto.

Vediamo se si può migliorare ulteriormente.

\newpage
\subsection{RandomForest}
\subsubsection{Risultati}
\begin{table}[ht]
	\centering
	\begin{tabular}{p{0.4\linewidth}p{0.4\linewidth}}
		Coefficiente di correlazione & 0.9218     \\
		Errore medio assoluto        & 48.4379    \\
		Errore quadratico medio      & 92.3005    \\
		Errore assoluto relativo     & 35.6298 \% \\
		Errore quadratico relativo   & 40.826 \%  \\
	\end{tabular}
\end{table}
\includegraphics[width=\linewidth]{tex/img/result_randomForest.png}

Il RandomForest ha migliorato ulteriormente la performance, riducendo ancora l'errore medio.

Possiamo fare ancora di meglio?

\newpage
\subsection{M5P}

\begin{quote}
	\textit{
		L'algoritmo M5P combina un convenzionale albero decisionale con la
		possibilità di una funzione di regressione lineare alle foglie.
	}
\end{quote}

L'algoritmo ha presentato risultati migliori se si effettuava il pruning. I risultati seguenti sono con pruning.

\subsubsection{Modello risultante}
\includegraphics[width=\linewidth]{tex/img/model_m5p.png}

\newpage
\subsubsection{Risultati}
\begin{table}[ht]
	\centering
	\begin{tabular}{p{0.4\linewidth}p{0.4\linewidth}}
		Coefficiente di correlazione & 0.8951     \\
		Errore medio assoluto        & 52.6507    \\
		Errore quadratico medio      & 101.0392   \\
		Errore assoluto relativo     & 38.7286 \% \\
		Errore quadratico relativo   & 44.6912 \% \\
	\end{tabular}
\end{table}
\includegraphics[width=\linewidth]{tex/img/result_m5p.png}
Possiamo dire che l'algoritmo M5P ha presentato buone prestazioni, con un numero discreto di foglie, che 
quindi con solo 10 LinearModel

\newpage
\section{Scelta dell'algoritmo}

Mettiamo a confronto le performance dei vari algoritmi usati

\begin{table}[!htb]
	\resizebox{\linewidth}{!}{
		\begin{tabular}{l|l|l|>{\columncolor[HTML]{C0C0C0}}l|l|}
										 & LinearRegression & RandomTree  & RandomForest & M5P        \\
			Coefficiente di correlazione &   0.8056         & 0.8915      & 0.9218       & 0.8951     \\
			Errore medio assoluto        &   81.1316        & 53.9916     & 48.4379      & 52.6507    \\
			Errore quadratico medio      &   133.8985       & 105.6178    & 92.3005      & 101.0392   \\
			Errore assoluto relativo     &   59.6785 \%     & 39.7149 \%  & 35.6298 \%   & 38.7286 \% \\
			Errore quadratico relativo   &   59.2254 \%     & 46.7164 \%  & 40.826  \%   & 44.6912 \%
		\end{tabular}
	}
\end{table}

Il \textit{\textbf{Random Forest}} è stato quindi l'algoritmo che ha presentato risultati migliori;
si sperava in migliori performance con l' \textit{M5P}, ma forse il dataset di partenza non era
sufficientemente grande.

\newpage
\section{Implementazione}
L'implementazione del modello di ML è stato realizzato con Java, attraverso l'utilizzo delle API di Weka.

Andiamone ad osservare i componenti principali.

\subsection{PCPart.java}

La classe \textit{PCPart.java} rappresenta la rappresentazione astratta del nostro componente, e
la rappresentazione in formato JSON.

Essa sarà poi estesa e implementata dalle altre classi che rappresenteranno uno specifico componente
(RAM, CPU, GPU etc.)

\lstinputlisting[
language=Java,
firstline=11,
numbers=left,
breaklines = true,
basicstyle=\scriptsize\ttfamily
]{PCPFiller/src/main/java/it/simonvic/pcpfiller/parts/PCPart.java}

\newpage
\subsubsection{Memory.java}

Un'implementazione di \textit{PCPart.java} è \textit{Memory.java} che rappresenta le memorie RAM.

Il JSON su cui si basa è il seguente:
\begin{lstlisting}
{
	"memory": [
	{
		"brand": "ADATA",
		"model": "AD2S800B2G5-R 2 GB",
		"module_type": "DDR2",
		"speed": {
			"cycles": 800000000
		},
		"number_of_modules": 1,
		"module_size": {
			"total": 2000000000
		},
		"price_per_gb": [
			"EUR",
			"22.225"
		],
		"color": "Green",
		"first_word_latency": 12.5,
		"cas_timing": 5,
		"error_correction": "Non-ECC / Unbuffered",
		"price": [
			"EUR",
			"44.45"
		]
	},
}
\end{lstlisting}

\newpage

\subsubsection{Attributi di Memory e conversion in CSV}

La classe \textit{Memory} rappresenta quindi la singola entry di una memoria RAM. Di seguito possiamo 
vedere la conversione in CSV dei relativi attributi.

\begin{lstlisting}[language=Java, numbers=left, basicstyle=\scriptsize\ttfamily, breaklines=true]
public non-sealed class Memory extends PCPart {

	public static String getCSVHeader() {
		return """
		"brand","model","moduleType","speedMHz","modulesNumber","moduleSizeGB","pricePerGBEuro","color","firstWordLatency","casTiming","errorCorrection","priceEuro"
		 """;
	}

	@Override
	public String toCSV() {
		return """
		"%s","%s","%s",%f,%d,%f,%f,"%s",%f,%f,%b,%f""".formatted(
			brand, model, moduleType, speedMHz,
			modulesNumber, moduleSizeGB, pricePerGBEuro, color,
			firstWordLatency, casTiming, errorCorrection, priceEuro);
	}

	public enum ModuleType {
		DDR, DDR2, DDR3, DDR4
	}

	private String brand;
	private String model;
	private ModuleType moduleType;
	private Double speedMHz;
	private Integer modulesNumber;
	private Double moduleSizeGB;
	private Double pricePerGBEuro;
	private String color;
	private Double firstWordLatency;
	private Double casTiming;
	private Boolean errorCorrection;
	private Double priceEuro;

\end{lstlisting}

\newpage
\subsubsection{Conversione JSON root oject in CSV}

Il seguente metodo verrà chiamato quando si dovrà convertire il dataset JSON in formato CSV,
che consiste in un header (contenente i nomi degli attributi, e la lista di tutte
le entry convertite in CSV.

Con gli \textit{Stream} di Java, "costruiamo" gli oggetti con rappresentazione JSON in oggetti
per l'utilizzo nel nostro modulo Java e li convertiamo in stringhe in formato CSV.

\begin{lstlisting}[language=Java, numbers=left, basicstyle=\scriptsize\ttfamily, breaklines=true]
	public static class JSON extends PCPart.JSON {

		public static class Root extends PCPart.JSON.Root {

			@Override
			public String toCSV() {
				StringBuilder sb = new StringBuilder();

				sb.append(Memory.getCSVHeader());
				memory.stream()
					.map(PCPart.JSON::build)
					.map(PCPart::toCSV)
					.map(PCPart::replaceMissingDataWithToken)
					.forEach(csvEntry -> sb.append(csvEntry).append("\n"));

				return sb.toString();
			}
		}
\end{lstlisting}

Da notare che i vari campi \textit{null} sono sostuiti da un \\token (\textit{PCPFiller.getMissingToken()}),
che rappresenterà un dato mancante. Di default il token è "\textit{?}" (punto interrogativo), dato che
è il token di default anche in Weka GUI.

\textbf{NOTA}: Il token può essere cambiato specificandolo con l'opzione \textit{--missing-token} via CLI.

\newpage
\subsection{PCPartClassifier.java}
\textit{PCPartClassifier} e' un wrapper astratto per il \textit{Classifier} dalle API di Weka, il quale
fornirà dei metodi helper per astrarre e facilitare la classificazione di una \textit{PCPart}.

\lstinputlisting[
language=Java,
firstline=13,
numbers=left,
breaklines = true,
basicstyle=\scriptsize\ttfamily
]{PCPFiller/src/main/java/it/simonvic/pcpfiller/classifiers/PCPartClassifier.java}

\subsubsection{MemoryClassifier.java}

Un'esempio di implementazione di un \textit{PCPartClassifier} per la classificazione di una \textit{Memory}
\lstinputlisting[
language=Java,
firstline=12,
numbers=left,
breaklines = true,
basicstyle=\scriptsize\ttfamily
]{PCPFiller/src/main/java/it/simonvic/pcpfiller/classifiers/MemoryClassifier.java}

\newpage
\subsection{PCPFiller.java}

Abbiamo infine \textit{PCPFiller}, che si occuperà invece di allenare il modello,
valutarlo, eventualmente salvarlo e infine di fare il "filling", classificando
le instanze e sostituendo i dati mancanti con il valore predetto.
\begin{lstlisting}[language=Java, numbers=left, basicstyle=\scriptsize\ttfamily, breaklines=true]
public class PCPFiller {
	protected PCPartClassifier pcpClassifier;
	protected Instances dataset;

	public PCPFiller(PCPart.Type partType, Instances dataset) {
		this.pcpClassifier = PCPart.classifierOf(partType);
		this.dataset = dataset;
		dataset.setClass(dataset.attribute(pcpClassifier.getClassName()));
		try {
			this.dataset = removeAttributes(this.dataset, pcpClassifier.getAttributesToIgnore());
		} catch (Exception ex) {
			log.warn("Can't remove attributes: " + Arrays.toString(pcpClassifier.getAttributesToIgnore()));
			log.warn(ex);
		}
	}
	[...]
	public void fill() throws Exception {
		for (Instance i : dataset.stream().toList()) {
			i.setClassValue(pcpClassifier.classify(i));
		}
	}
	[...]
	/**
	 * Save the dataset in its current state to a file, using the specified format
	 *
	 * @param outputPath
	 * @param outputDatasetFormat
	 * @throws IOException
	 */
	public void saveDataset(Path outputPath, DatasetFormat outputDatasetFormat) throws IOException {
		switch (outputDatasetFormat) {
			case ARFF -> saveDatasetARFF(outputPath);
			case CSV -> saveDatasetCSV(outputPath);
			case JSON -> saveDatasetJSON(outputPath);
		}
	}

	/**
	 * Save the dataset in ARFF format
	 *
	 * @param outputPath
	 * @throws IOException
	 */
	private void saveDatasetARFF(Path outputPath) throws IOException {
		Files.write(outputPath, dataset.toString().getBytes(), StandardOpenOption.CREATE);
	}
\end{lstlisting}

\newpage
\section{Test run}

Eseguiamo una test run del nostro modulo Java...

\includegraphics[width=\linewidth]{tex/img/testrun.png}

Come si può notare dalle statistiche, siamo passati da un dataset di 7158 instanze, di cui solo
il 25\% utilizzabile (1791 instanze), ad un dataset utilizzabile al 100\% !

Ora si potrebbe facilmente caricare il modello salvato in \textit{/tmp/memory.model} su Weka,
per succesive analisi o test.
Lo stesso vale per il dataset completeo (\textit{/tmp/dataset.arff})!

\section{Futuro}

Ora non resta che espandere il nostro progetto per poter supportare tutti i tipi di componenti;
si potrebbe anche migliorare ulteriormente automatizzando la scelta degli attributi da scartare/usare
per le predizioni!

E perchè no? Estendere il progetto ad altri tipi di dataset?

\end{document}
